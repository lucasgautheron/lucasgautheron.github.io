<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://lucasgautheron.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://lucasgautheron.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-30T08:07:19+00:00</updated><id>https://lucasgautheron.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">La démocratie comme machine épistémique: comprendre la prospérité d’Athènes</title><link href="https://lucasgautheron.github.io/posts/2022/09/epistemic-democracy/" rel="alternate" type="text/html" title="La démocratie comme machine épistémique: comprendre la prospérité d’Athènes"/><published>2022-09-15T00:00:00+00:00</published><updated>2022-09-15T00:00:00+00:00</updated><id>https://lucasgautheron.github.io/posts/2022/09/epistemic-democracy</id><content type="html" xml:base="https://lucasgautheron.github.io/posts/2022/09/epistemic-democracy/"><![CDATA[<p>Dans ce qui suit, je souhaite discuter de deux ouvrages complémentaires qui stimulent le débat sur les vertus et faiblesses de la démocratie, dans un contexte où le changement climatique, mais aussi la confrontation à des régimes autoritaires hostiles, pose de manière urgente la question de sa capacité à affronter et gérer les crises.</p> <p>Les deux ouvrages en question affirment aborder la démocratie sous un angle relativement peu discuté, celui de sa performance <em>épistémique</em>. Par là on entend, selon les points de vue, la capacité de la démocratie à guider l’action publique de manière informée, ou encore sa capacité à produire des jugements relativement “pertinents”, “exacts”, ou “vrais”. Les ouvrages abordent tous deux cette vaste question mais de manières bien différentes.</p> <p>Le premier, <em>Democracy and Knowledge: Innovation and Learning in Classical Athens</em> de J. Ober <sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, est une étude de cas qui se concentre sur une forme particulière de démocratie bien distincte de nos “démocraties” contemporaines. Ober introduit d’ailleurs son ouvrage par une mise en exergue des différences fondamentales entre la démocratie Athénienne et, par exemple, la démocratie américaine. De son côté, <em>Democratic Reason: Politics, Collective Intelligence, and the Rule of the Many</em> de H. Landemore <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup> est beaucoup plus théorique, et discute de la démocratie dans un sens plus large et en des termes assez généraux (en discutant, par exemple, des propriétés épistémiques du “majoritarisme”).</p> <figure> <img src="/assets/img/democratie-epistemique/image.jpg" height="7em"/> <figcaption>Couvertures de <em>Democracy and Knowledge: Innovation and Learning in Classical Athens</em> et <em>Democratic Reason: Politics, Collective Intelligence, and the Rule of the Many</em></figcaption> </figure> <p>Ober et Landemore, cependant, soutiennent tous deux qu’il reste à mieux cerner les éventuelles vertus épistémiques de la démocratie, c’est-à-dire sa faculté à tirer partie des savoirs individuels pour les mettre au profit de l’action collective. Il faut donc aller au-delà des discussions usuelles autour de la démocratie, qu’ils s’agissent de conceptions éthiques normatives, ou encore de conceptions issues de la théorie du choix social qui tendent à réduire la démocratie à un arbitrage entre les préférences de différents groupes. Les implications des travaux dans la tradition de celle d’Ober et Landemore ont des implications importantes. Anthropologiques d’abord, car ils participent à comprendre comment l’Homme parvient à exploiter ses capacités hypersociales pour bâtir des formes de coopération complexes exploitant le “cerveau collectif” <sup id="fnref:7"><a href="#fn:7" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>. Politiques ensuite, car ils donnent des bases robustes pour défendre des formes institutionnelles démocratiques. En mettant en avant leur fonction épistémique, ces travaux remettent la balle dans le camp des critiques de la démocratie, à qui revient la charge de prouver que des arrangements institutionnels alternatifs apportent au moins les mêmes bénéfices de ce point de vue. </p> <h2 id="democracy-and-knowledge--la-démocratie-athénienne-comme-machine-épistémique"><em>Democracy and Knowledge</em> : La démocratie Athénienne comme machine épistémique</h2> <p>Dans <em>Democracy and Knowledge</em>, Ober propose de se demander si l’“idéal normatif” que représente la démocratie “participative” n’introduit pas des coûts qui dépassent les bénéfices, dont la nature est avant tout épistémique, que l’on peut en tirer. Il propose donc d’évaluer la démocratie selon sa capacité à coordonner efficacement l’action des membres d’une société dans laquelle le “savoir utile” qui permettrait de mieux diriger l’action collective est dispersé.</p> <p>L’hypothèse centrale de l’ouvrage est formulée de la façon suivante :</p> <blockquote> <p>« L’Athènes démocratique était capable de tirer partie de sa taille et de ses ressources, et ainsi de rivaliser avec succès au fil du temps contre des adversaires organisés de manière hiérarchique, car le coût des pratiques politiques participatives était inférieur aux gains issus de la coopération sociale résultant de savoir utile tel qu’il était organisé et déployé dans le contexte favorable à l’innovation et fondé sur l’apprentissage des institutions et de la culture démocratique. (p. 37) »</p> </blockquote> <p>Ainsi la démocratie Athénienne, pour Ober, a permis de dégager efficacement des solutions à des problèmes complexes d’action collective, à tel point que celle-ci était plus compétitive que la plupart de ses rivaux organisés de façon hiérarchique. En effet, la cité-État était soumise à des menaces existentielles de façon quasiment continue (guerres, épidémies), et en dépit de cela la nature démocratique des institutions athéniennes a pu perdurer pendant environ six générations. La thèse d’Ober se veut donc une réfutation de la loi de Fer de Michels, selon laquelle les démocraties, inefficaces, dégénèrent inéluctablement en oligarchies. Ober ne nie pas que la démocratie puisse occasionnellement échouer, et même dramatiquement (l’exemple célèbre de la débâcle Athénienne consécutive à l’expédition de Sicile en est une preuve). Il défend simplement que les bénéfices dépassent les coûts, y compris ceux résultant de choix parfois erronés.</p> <p>Pour soutenir sa thèse, Ober commence par établir la prospérité exceptionnelle d’Athènes durant la période classique, à l’aide de plusieurs indicateurs quantitatifs (richesse matérielle, “renomée”, nombre de bâtiments publics, etc.), lesquels démontrent la singularité de la cité. Il suggère en outre, toujours à l’appui de données quantitatives, que l’on peut raisonnablement attribuer la prospérité exceptionnelle d’Athènes au caractère exceptionnellement démocratique de ses institutions, car les avancées démocratiques <em>précèdent</em> les phases de progrès (tel que mesuré via différents indicateurs).</p> <p>Dans le chapitre suivant, Ober formule plus précisément le problème auquel était confronté Athènes. Sous une menace perpétuelle de destruction par ses différents rivaux, elle devait, pour sa survie, tirer partie au mieux de ses ressources, et en particulier de sa taille. Mais si la coordination d’une petite communauté est relativement simple, elle ne va pas de soi pour une unité politique de la taille d’Athènes. Tout l’enjeu est donc d’inciter les individus à coopérer, d’une manière qui mette efficacement le savoir à leur disposition au profit de l’action collective dans un contexte “écologique” extrêmement compétitif. C’est au regard de leur capacité à remplir cette fonction que les institutions athéniennes doivent être jugées. Ober explicite la dimension épistémique du problème en distinguant trois types de savoirs. Le savoir social d’abord, qui comprend tout type de savoir nécessaire utile au bon fonctionnement des processus participatifs (par exemple, à qui peut-on faire confiance concernant tel ou tel le sujet). Deuxièmement, Ober considère le savoir technique “spécialisé”, autrement dit l’expertise que certains individus peuvent posséder dans divers domaines, et qui doit être mise au profit de l’action collective. Ober propose de reconnaître une troisième catégorie de savoirs (les savoirs “latents”), plus diffus et tacites que les savoirs détenus par des experts, et dont l’exploitation profite sans doute le plus de processus participatifs, lesquels permettent de ramener à la “surface” ces savoirs “dispersés”.</p> <p>Dans le reste de l’ouvrage, Ober entend montrer comment les institutions Athéniennes accomplissaient effectivement leur fonction par le biais de trois stratégies à caractère épistémique, à savoir l’“aggrégation”, l’“alignement” et la “codification”.</p> <p>L’aggrégation, d’abord, consiste à rassembler efficacement les savoirs utiles dispersés de sorte à les mettre au bénéfice de l’action publique. La mise en action de cette capacité est illustrée par l’exemple d’un décret organisant une expédition en vue d’établir une base navale. Ce décret, très détaillé, illustre la manière dont des connaissances “militaires, financières, climatiques, et légales” disparates ont du être combinées pour la bonne organisation et la bonne exécution de l’expédition. Afin de montrer en quoi cela requiert une construction institutionnelle, Ober discute le problème en terme de réseau social, c’est-à-dire le réseau qui caractérise les liens entre les individus composant la population Athénienne. Ce réseau, initialement, devait être constitué de groupes de gens très connectés entre eux (par exemple au sein d’un village), mais avec très peu d’interactions entre les groupes. Un tel réseau n’est pas propice à l’aggrégation à large échelle des savoirs des individus. Les institutions athéniennes, en regroupant les “demes” (unités admnistratives fondamentales) au sein des “tribus”, a permis de décloisonner ce réseau social. Les interactions entre les demes au sein des tribus sont en effet alors stimulées par des rituels mais aussi par leur participation conjointe aux opérations militaires. De la même manière, la Boulê, un conseil de 500 citoyens équitablement répartis à travers les 139 demes responsable de l’ordre du jour des Assemblées, stimulait fortement la formation de liens parmi le réseau social des Athéniens, leur permettant ainsi de mieux faire profiter l’ensemble des savoirs et de l’expertise des uns et des autres <sup id="fnref:8"><a href="#fn:8" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>. Cette position privilégiée des bouleutes leur conférait par ailleurs des bénéfices symboliques et sociaux, qui, complétés plus tard par une indemnité financière, encourageaient la bonne participation au processus démocratique <sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. Ober montre que l’on peut analyser un certain nombre de procédures institutionnelles sous le prisme de leurs vertus épistémiques agrégatives. Il les contraste en outre à un modèle “élitiste”, en soulignant qu’une part importante des citoyens occupe au moins une position privilégiée dans ce réseau à un moment donné (e.g. en tant que bouleute ou magistrat), et que les citoyens “politiquement actifs” deviennent de plus en plus représentatif de la population au cours du temps.</p> <p>L’alignement, ensuite, concerne les processus qui visent la mise en action des savoirs aggrégés, par la mise en application des décisions que ces savoirs ont participé à informer. Or, dans un cadre institutionnel aussi décentralisé que la démocratie Athénienne, sans “chaîne de commande” clairement établie, la manière dont chacun “aligne” son action de sorte à coopérer aux objectifs poursuivis par la communauté ne va pas de soi. En particulier, si la coopération a un coût élevé (par exemple lorsqu’il s’agit de participer à la mobilisation militaire), elle n’est possible que si chacun sait que chacun autour de lui possède également l’information qu’il doit coopérer. Par conséquent l’alignement nécessite, dans un environnement institutionnel décentralisé, le partage d’un certain <em>savoir commun</em> (d’où sa nature épistémique). Ober décrit donc la manière dont un tel savoir commun pouvait être engendré par les institutions athéniennes. Les tribunaux, par exemple, permettent de sanctionner les défecteurs, montrant ainsi à tous que les institutions assurent la coopération de chacun. D’autres aspects de la démocratie Athénienne, cependant, participaient à la <em>publicité</em> de ces savoirs communs. Selon Ober, l’architecture de nombreux édifices publics spécialement conçus sous l’ère démocratique, avait pour caractéristique de favoriser l’“intervisibilité” des uns et des autres, ce qui était particulièrement propice au partage simultané de ces savoirs parmi une foule. C’est le cas par exemple du Pnyx, où se réunissaient des milliers citoyens lors des Assemblées, mais aussi des théâtres des demes, lesquels semblent aussi avoir eu des fonctions politiques en propageant ces savoirs communs au-delà du coeur d’Athènes.</p> <p>La troisième et dernière stratégie à valeur épistémique des institutions athéniennes soutenant l’efficacité de l’action collective, selon Ober, est la <em>codification</em>. Par là, Ober désigne divers moyens encourageant la productivité, le commerce extérieur et l’économie de marché en diminuant les coûts de transaction, tels que “[des] règles formelles (par exemple les “lois” et “décrets”), des “procédures de litige” ouvertes, des dispositifs de “sanction”, des “moyens d’échange” et leur standardisation (en particulier, Ober développe longuement la prévention de la contrefaçon des pièces de monnaie), et la lutte contre les distorsions du marché (corruption, recherche de rente, etc.). La particularité de ces stratégies, dans le cadre des institutions athéniennes, étant de ne pas reposer sur un pouvoir central et hiérarchisé, qui serait trop rigide et donc peu apte à innover. Les procédures “ouvertes” et “impartiales” garanties par les institutions athéniennes étaient particulièrement favorables à la bonne conduite des affaires, et selon Ober, instauraient un climat de confiance et de prédictibilité propice à des pratiques comme celle du crédit.</p> <p>Ober soutient donc de manière assez conséquente que les institutions démocratiques athéniennes avaient pour fonction non pas “d’aggréger des préferences, mais du savoir”, et que c’est de là qu’Athènes tirait sa force dans la compétition avec ses rivaux. En effet, Ober illustre comment une innovation culturelle a permis à une population de mieux tirer partie des capacités sociales de l’être humain pour établir des formes de coopération à plus vaste échelle. L’ouvrage d’Ober a des répercussions intéressantes, si l’on fait un parallèle avec l’ouvrage de Joseph Henrich, <em>The WEIRDest people in the world</em> <sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">6</a></sup>. Dans ce livre, Henrich soutient que, en réponse à des transformations imposées notamment par l’Église et qui ont fragilisé les structures sociales fondées sur la parenté ou les rapports claniques, les Occidentaux ont développé des traits psychologiques particuliers, tels qu’une certaine aptitude à nouer des relations avec des étrangers, ou encore à réaliser des calculs d’utilité à long terme. En retour, ces traits psychologiques, propices au bon fonctionnement de l’économie de marché et à la démocratie, expliquent selon lui prospérité de l’Occident. Là où dans le récit d’Henrich, les transformations qui ont facilité la coopération à grande échelle sous des modalités peu hiérarchiques (comme la démocratie ou le marché) se sont déroulés sur plusieurs siècles, il est intéressant de remarquer que les Athéniens sont parvenus à établir une organisation coopérative démocratique assez rapidement, en développant un environnement institutionnel propice à des relations interpersonnelles dépassant les cercles sociaux immédiats. Reste cependant à comprendre comment de telles institutions ont pu émerger.</p> <p>Pour Ober, la révolte populaire qui a libéré Athènes du joug des Spartiates, et qui a déclenché la fondation de ses premières institutions démocratiques, a créé le sentiment d’appartenance (l’asabiyya, pourrait-on dire <sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">7</a></sup>) propice à l’émergence d’une aptitude des Athéniens à coopérer et ce à une échelle qui dépassait largement celle des cercles de parenté des individus. On est tenté d’en conclure que la démocratie, en tout cas Athénienne, est une innovation largement due à la guerre, laquelle nourrit non seulement le sentiment d’appartenance et de cohésion parmi les “citoyens”, mais stimule aussi l’édification de formes de coopération efficaces à travers la contrainte fondamentale et urgente qu’elle impose (celle de surpasser ses rivaux) <sup id="fnref:9"><a href="#fn:9" class="footnote" rel="footnote" role="doc-noteref">8</a></sup>. On peut donc penser que les contraintes existentielles fortes sont propices à l’innovation institutionnelle, et donc peut-être à l’apparition de mécanismes de coopération nouveaux et efficaces. Observera-t-on le même phénomène en réponse au changement climatique?</p> <p>Il est tentant, en effet, de chercher a tirer des conclusions “pratiques” de l’ouvrage d’Ober, en transposant le raisonnement à nos institutions politiques. Cependant, les institutions athéniennes fonctionnaient à une échelle incomparable à celle des Etats-Nations contemporains. Et il y a des raisons fortes de penser que le rapport coût/bénéfice d’un tel schéma institutionnel dépende de son échelle. C’est pour cela qu’Ober propose plutôt d’envisager les implications de son analyse vis-à-vis d’organisations plus petites, qu’il s’agisse d’institutions politiques locales, ou bien d’entreprises. Ober donne en effet des bases solides pour soutenir la pertinence d’une organisation démocratique des moyens de production. Ce n’est pas pour rien que celui-ci récupère une formule attribuée au PDG de HP (“Si HP savait ce que HP sait, nous serions trois fois plus rentables”) pour la transposer au cas Athénien (Si seulement Athènes savait ce qu’Athènes sait). Quand bien même il serait difficile d’en tirer des conclusions pratiques, l’ouvrage a ceci d’exceptionnel qu’il rend compte dans le détail d’éléments historiques concrets à l’aide d’outils théoriques divers issus des sciences politiques et économiques, de l’épistémologie sociale, mais aussi de l’anthropologie.</p> <h2 id="democratic-reason--les-vertus-épistémiques-de-la-démocratie"><em>Democratic Reason</em> : les vertus épistémiques de la démocratie</h2> <p>Dans son ouvrage <em>Democratic Reason: Politics, Collective Intelligence, and the Rule of the Many</em>, Landemore propose de défendre la supériorité épistémique de la démocratie (par rapport à des modes de décision tyranniques ou oligarchiques) sur des bases théoriques. Elle s’appuie donc bien davantage sur la littérature philosophique et épistémologique concernant la démocratie que ne le fait Ober. Le livre est d’ailleurs principalement une réponse théorique aux critiques diverses (et théoriques aussi) portées contre la fiabilité de la démocratie. Ainsi, là où Ober explore les effets concrets d’un arrangement institutionnel précis, Landemore répond à des critiques théoriques générales par des arguments du même ordre.</p> <p>Dans son effort de défense de la supériorité épistémique de la démocratie, Landemore commence par énumérer les nombreuses critiques qui semblent s’opposer à sa tentative. Ces critiques visent d’abord la foule, jugée “ignorante”, “irrationnelle”, “apathique” <sup id="fnref:10"><a href="#fn:10" class="footnote" rel="footnote" role="doc-noteref">9</a></sup>, mais aussi les procédures démocratiques elles-mêmes. En effet, les biais cognitifs humains sont bien documentés, et de nombreux théorèmes établissent en fait l’impossibilité en général, pour des procédures démocratiques, de produire des jugements collectifs successifs “raisonnablement” cohérents.</p> <p>Puis, l’ouvrage se poursuit avec une “généalogie” des références théoriques au caractère épistémique de la démocratie, ou plus généralement l’idée d’une intelligence collective qui transcende l’intelligence des individus. On y trouve notamment des références telles que Rousseau ou Condorcet (à qui l’on doit le théorème du Jury, qui fournit une défense statistique de la rationnalité du jugement majoritaire, voir plus bas). En s’appuyant sur Mill et Hayek, Landemore évoque par ailleurs des théories libérales alternatives de la supériorité de la raison collective, telles que le concept de “libre marché des idées” (Mill) ou bien encore la défense de la performance épistémique des marchés de prédiction. Il est intéressant de souligner que la démocratie ne totalise pas l’ensemble des stratégies non hiérarchiques exploitant le potentiel de l’“intelligence collective”.</p> <p>L’ouvrage discute ensuite séparment de deux processus démocratiques : la délibération d’abord, puis le jugement majoritaire. Pour chacun, Landemore élabore une défense de leur potentiel épistémique, puis examine les critiques qui pointent les circonstances sous lesquelles ces processus peuvent échouer. L’ouvrage évoquant une multitude d’arguments de façon relativement détaillée, je ne proposerai qu’une description très superficielle de son propos.</p> <p>On peut apprécier la délibération, selon Landemore, pour sa performance lors de tâches de résolution de problème. Dès lors, la délibération est un processus efficace, capable de faire émerger des solutions qui n’avaient été envisagées par aucun individu pris séparément. La clé de l’efficacité de la délibération “inclusive” est, selon Landemore, le niveau de “diversité cognitive” au sein du groupe délibérant. Ce besoin de diversité requiert éventuellement des précautions particulières pour passer à l’échelle, car ce type de processus n’est pas fonctionnel pour des groupes trop grands, et la représentation risque d’affecter le niveau de diversité du groupe ; mais ces précautions, soutient-elle, ne sont pas insurmontables. Landemore propose ensuite de s’attaquer à un certain nombre d’objections qui pointent les divers biais cognitifs dont sont victimes les humains et qui peuvent sembler compromettre, a priori, la nature épistémique de la libération. Plutôt que de réfuter les preuves empiriques manifestes de ces limitations, Landermore s’appuie sur la théorie argumentative du raisonnement de Hugo Mercier et al., selon laquelle notre faculté de raisonnement vise “à trouver et évaluer des raisons, de sorte à ce que les individus puissent convaincre les autres et évaluer leurs arguments”. En ce sens, la faculté de raisonnement est faillible au niveau individuel (certes), car son véritable potentiel épistémique est exploité au mieux de manière sociale, en cherchant à convaincre les autres et en leur faisant éprouver nos arguments. Ainsi pour Landemore, les usages “normaux” de notre faculté de raisonnement sont “délibératives et sociales”.</p> <p>Landermore s’attaque ensuite au jugement majoritaire. Une justification connue de la valeur épistémique du jugement majoritaire est donnée par le théorème du Jury de Condorcet. Selon ce théorème, sous réserve de trois conditions, la probabilité qu’un vote majoritaire retienne la proposition “vraie” parmi deux propositions tend vers 1 lorsque le nombre de votants tend vers l’infini. Les trois conditions pour cela sont les suivantes :</p> <ol> <li>Chaque votant a une probabilité $&gt; 1/2$ de choisir la proposition vraie (biais pour la vérité)</li> <li>Chaque votant vote indépendamment du jugement des autres</li> <li>Chaque votant vote “sincèrement”</li> </ol> <p>Si chaque individu possède une probabilité de choisir l’option correcte à peine plus grande que $1/2$, par exemple de 51 %, alors pour une assemblée de 1000 personnes le jugement majoritaire sera correct 73 % du temps. En ce sens, le jugement collectif est supérieur au jugement individuel de l’<em>ensemble</em> des individus. La question reste de savoir dans quelle mesure les conditions du théorème du Jury sont effectivement applicables à des situations réelles dignes d’intérêt. Landemore propose quelques arguments en ce sens, qu’on peut ne pas trouver parfaitement convaincants. D’autres arguments en faveur du jugement majoritaire sont présentés. Par exemple, Landemore propose plusieurs exemples regroupés sous le terme “miracle aggrégatif”, comme celle d’une situation où seule une minorité connaît la vérité, les autres étant totalement ignorants ; ou bien l’exemple d’une foule devinant avec une bonne précision le poids d’un boeuf, la moyenne des estimations individuelles étant correcte à 500 grammes près, alors que celles-ci sont relativement dispersées. On peine à voir en quoi ces exemples ne sont pas des variantes du théorème de Condorcet. Une autre justification de la force épistémique du jugement majoritaire repose sur des conditions différentes : le cas où les jugements individuels, au lieu d’être indépendants, sont fortement anti-corrélés. Le principe est grossièrement que les jugements individuels sont biaisés, mais, à condition que le groupe possède le bon niveau de “diversité cognitive”, et que les biais soient distribués symétriquement, ceux-ci se compensent les uns les autres et s’annulent. L’argumentaire développé pour soutenir cette description évoque à la lecture un biais centriste, selon lequel le jugement médian est le plus correct en moyenne. Bien sûr l’argument échoue si la foule dans son ensemble possède un biais global non-nul (elle cite Bryan Caplan qui reproche aux électeurs leurs biais anti-marché), mais Landemore évoque des solutions (par exemple, l’éducation peut corriger ces biais avec le temps).</p> <p>Enfin, Landemore défend ce qu’elle nomme “cognitivisme politique”, à savoir que l’on peut soutenir une notion de “vérité” ou d’“exactitude” applicable aux options qui s’offrent à la décision politique, de sorte qu’il existe en général “des réponses meilleures” ou “pires” que d’autres en ce qui concerne les questions politiques. En soutien de cette idée, Landemore met en avant des exemples de décisions manifestement mauvaises (l’expédition de Sicile mentionnée plus haut, ou encore la guerre en Irak), lesquels suggèrent qu’il existe au moins un standard de “vérité” applicable dans un certain périmètre. Landermore discute certaines difficultés en travers du cognitivisme politique, comme le recours à des valeurs fondamentales. Un cognitivisme politique culturel admettrait un coeur de valeurs contingentes (historiquement situées) comme standard de “vérité”. Un cognitivisme politique absolu, au sens faible, considérait des critères universels (en valorisant les décisions qui conduisent à éviter “guerres”, “famines” et “génocides”). Enfin, pour Landemore, un cognitivisme absolu fort considérait un principe universel au périmètre large tel que la recherche d’optimums de Pareto <sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">10</a></sup>. On repense alors au cas du livre d’Ober, pour lequel la solution au problème est assez directe : Athènes étant plongée dans un environnement écologique compétitif (composé d’adversaires hostiles) et soumis à diverses menaces existentielles, sa survie fonde un standard de vérité plutôt évident. Ces exemples montrent en tout cas qu’un relativisme total est une position intenable, et qu’il faut bien concéder un certain degré de pertinence au “cognitivisme politique”.</p> <p>En conclusion, Landemore cite un autre argument intéressant à opposer aux critiques de la démocratie qui soulèvent des dérives historiques d’oppression de minorités. Pour elle, il faut admettre que la démocratie est aussi un processus temporel, capable d’apprendre de ses erreurs. Une telle capacité d’apprentissage, souligne-t-elle, requiert une forme de mémoire, produite par les institutions, qu’elle nomme “artefacts cognitifs”, citant en exemple les textes constitutionnels. Cela rejoint les propos d’Ober, qui soutient que la démocratie produit un bon compromis entre l’apprentissage par routinisation (qui diminue les coûts de transaction et de coopération) et l’innovation (qui permet de s’adapter à un environnement fluctuant).</p> <p>Les arguments de Landemore ne sont pas forcément parfaitement convaincants. Rappelons que celle-ci définit la démocratie comme “une procédure de décision collective […] inclu[ant], plus ou moins directement, tous les membres du groupe pour lequel des décisions doivent être faites”. En particulier, Landemore n’exclut pas la démocratie représentative. Par contraste, Ober insistait bien sur la nécessité de distinguer la démocratie participative Athénienne de nos démocraties représentatives contemporaines ; et sa thèse, portant sur l’effet d’un arrangement particulier (quoique dynamique), était sans doute moins ambitieuse. Un problème, peut-être, avec l’ouvrage de Landemore, est de chercher à vouloir monter une défense trop générale de la démocratie, alors que ce concept comprend des formes institutionnelles diverses, découlant d’imitations approximatives et d’innovations successives, de tel sorte que le lien entre celles-ci est relativement ténu (et les jugements généraux à leur sujet automatiquement plus fragiles). Pour autant, Landemore offre une bonne vue générale des problèmes autour de la pertinence de la démocratie d’un point de vue épistémique, et condense des arguments intéressants. Il s’agit d’une excellente entrée en matière pour qui souhaite approfondir le sujet.</p> <p><em>Merci à PopulusRe pour les recommandations de lecture…</em></p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Ober, J., 2010, <em>Democracy and Knowledge: Innovation and Learning in Classical Athens</em>, Princeton University Press <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>Landemore, H., 2017, <em>Democratic Reason: Politics, Collective Intelligence, and the Rule of the Many</em>, Princeton University Press <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:7"> <p>Henrich, J., 2017, <em>The Secret of Our Success: How Culture Is Driving Human Evolution, Domesticating Our Species, and Making Us Smarter</em>, Princeton University Press <a href="#fnref:7" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:8"> <p>Par ailleurs, le mode de désignation des bouleutes comprend du tirage au sort, qui constitue un processus non biaisé d’exploration de l’espace des savoirs et idées dans le cerveau collectif. <a href="#fnref:8" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>Il existait à l’inverse des mécanismes de sanction pour décourager les comportements non coopératifs. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>Henrich, J., 2020, <em>The WEIRDest people in the world: How the west became psychologically peculiar and particularly prosperous</em>, Farrar, Straus and Giroux <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>L’asabiyya est un terme arabe qui désigne la cohésion interne d’un groupe. Le concept est exploité par Peter Turchin dans (2017) dans son ouvrage <em>War and Peace and War: The Rise and Fall of Empires</em>, dans lequel il propose une théorie générale de la formation des empires et de leur déclin. <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:9"> <p>On peut avancer l’hypothèse que la démocratie soulage la contradiction masse/elite qui affaibilit la cohésion interne nécessaire à l’effort de guerre, dans l’esprit de la théorie de Turchin (ibid., <sup id="fnref:5:1"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">7</a></sup>). <a href="#fnref:9" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:10"> <p>Par exemple, puisque chaque vote n’a qu’une incidence négligeable, les individus n’auraient pas intérêt à prendre le temps de s’informer correctement pour former leur décision, le coût étant bien supérieur au bénéfice. D’un point de vue utilitariste les citoyens n’ont pas intérêt à prendre le temps de former un choix “éduqué” et informé. <a href="#fnref:10" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:6"> <p>Un optimum de Pareto est une configuration dans laquelle on ne peut améliorer le sort de personne sans empirer celui des autres. <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="posts"/><category term="social epistemology"/><category term="political science"/><category term="french"/><summary type="html"><![CDATA[Dans ce qui suit, je souhaite discuter de deux ouvrages complémentaires qui stimulent le débat sur les vertus et faiblesses de la démocratie, dans un contexte où le changement climatique, mais aussi la confrontation à des régimes autoritaires hostiles, pose de manière urgente la question de sa capacité à affronter et gérer les crises.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://lucasgautheron.github.io/democratie-epistemique/image.jpg"/><media:content medium="image" url="https://lucasgautheron.github.io/democratie-epistemique/image.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">Le nucléaire, ‘plus intermittent’ que l’éolien?</title><link href="https://lucasgautheron.github.io/posts/2022/08/eolien-nucleaire-intermittent/" rel="alternate" type="text/html" title="Le nucléaire, ‘plus intermittent’ que l’éolien?"/><published>2022-08-02T00:00:00+00:00</published><updated>2022-08-02T00:00:00+00:00</updated><id>https://lucasgautheron.github.io/posts/2022/08/nuclear-wind-post</id><content type="html" xml:base="https://lucasgautheron.github.io/posts/2022/08/eolien-nucleaire-intermittent/"><![CDATA[<p>Des personnalités politiques de premier plan de la France Insoumise affirment depuis plusieurs mois que le nucléaire est une source d’électricité “intermittente” <sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>, et même bientôt “plus intermittent[e] que l’éolien” si l’on en croit Jean-Luc Mélenchon <sup id="fnref:2"><a href="#fn:2" class="footnote" rel="footnote" role="doc-noteref">2</a></sup>. Ce discours, bien sûr, vise à promouvoir la transition vers 100% d’énergies renouvelables défendue par le parti. Une telle transition impliquerait de fermer les 56 réacteurs actuellement en opération, lesquels ont fourni à la France 70% de son électricité en 2019 <sup id="fnref:3"><a href="#fn:3" class="footnote" rel="footnote" role="doc-noteref">3</a></sup>. Une telle tâche n’est pas seulement difficile ; elle est aussi critiquable, alors que l’énergie nucléaire demeure à ce stade la source la plus propre en terme de gaz à effet de serre. Alors que le bien-fondé de la sortie du nucléaire en Allemagne est remise en question par les menaces actuelles sur l’approvisionnement en gaz et par ses conséquences en terme d’émissions de gaz à effet de serre, LFI et ses alliés d’EELV ont besoin de renforcer leurs arguments contre l’énergie nucléaire. Par chance pour eux, le parc nucléaire français rencontre actuellement des difficultés majeures. Environ la moitié des réacteurs sont arrêtés pour des opérations de maintenance, pour diverses raisons, y compris le fameux problème de corrosion sous contrainte anormale identifié sur plusieurs d’entre eux. Il en résulte que la disponibilité du parc nucléaire est actuellement très limitée, et un risque de blackout pour cet hiver. C’est principalement sur la base de cette situation que le nucléaire est qualifié d’“intermittent” par la France Insoumise, et même “bientôt plus intermittent que l’éolien”.</p> <h2 id="quantifier-lintermittence">Quantifier l’intermittence</h2> <p>Qu’en est-il vraiment ? Pour répondre à cette question encore faut-il savoir ce que l’on entend par intermittent. Par source d’énergie intermittente, pour ma part, j’entends une source d’énergie qui ne garantit pas la livraison d’une quantité de puissance désirée de manière fiable. Peut-on quantifier l’intermittence du nucléaire et de l’éolien en ces termes ? Grâce aux données publiques du mix énergétique français, c’est possible. Ces données comprennent la puissance produite filière par filière et demi-heure par demi-heure entre 2012 et 2021 <sup id="fnref:4"><a href="#fn:4" class="footnote" rel="footnote" role="doc-noteref">4</a></sup>; ainsi que la puissance installée par unité de production et leur date de mise en service <sup id="fnref:5"><a href="#fn:5" class="footnote" rel="footnote" role="doc-noteref">5</a></sup>. Ces données, une fois combinées, permettent d’estimer la puissance installée nécessaire pour garantir la livrasion d’une quantité de puissance souhaitée avec certain taux de fiabilité (i.e., une certaine fration du temps). Cela permet de répondre à des questions telles que : combien faut-il installer d’éoliennes pour obtenir au moins 1 GW (la puissance typique d’un réacteur nucléaire) 90% de l’année ? Les résultats sont donnés ci-dessous, et la méthodologie est explicitée et discutée plus bas.</p> <figure> <img src="/assets/img/nuclear-wind/puissance_installee_garanti_annee.png" alt="" style="max-width: 800px"/> <figcaption>Puissance installée requise pour garantir une puissance disponible d'1 GW minimum avec un certain taux de disponibilité sur l'année, pour l'éolien et le nucléaire. Données du parc français. Les courbes continues représentent les valeurs moyennes. Les zones colorées représentent les variations d'une année sur l'autre.</figcaption> </figure> <p>On observe que l’éolien et le nucléaire ont deux comportements très différents. Pour le nucléaire, il suffit d’avoir environ 2 GW installés (soit environ 2 réacteurs) pour garantir 1 GW disponible près de 100% de l’année. Par rapport au critère plus haut, le nucléaire est relativement fiable et donc “non-intermittent”. Pour l’éolien, en revanche, garantir la livraison d’un GW avec une haute disponibilité requière une puissance installée faramineuse. Il faut 18,4 GW pour garantir 1GW dispo 90 % de l’année. Soit typiquement 6000 éoliennes de 3 MW chacune…. À comparer avec les 1,7 réacteurs nécessaires.</p> <p>Le graphe ci-dessus tient compte de la variabilité de disponibilité du parc d’une année sur l’autre (très mauvaise en ce moment pour le nucléaire), laquelle est représentée par les bandes de couleurs autour des courbes. Même en tenant compte de la faible disponibilité actuelle du parc, donc, il n’y a aucune comparaison entre le nucléaire et l’éolien en terme d’intermittence.</p> <p>Ci-dessous, le même graphique est produit pour les données correspondant aux mois d’hiver seulement (décembre à mars inclus), où 1) il y a plus de vent et 2) la demande est plus importante, de sorte qu’EDF s’arrange pour que le parc nucléaire soit davantage disponible (et donc que son facteur de charge soit meilleur). On observe bien ces deux effets, car la puissance installée nécessaire dans un cas comme dans l’autre est plus faible. Mais la distinction demeure nette :</p> <figure> <img src="https://lucasgautheron.github.io/assets/img/nuclear-wind/puissance_installee_garanti_hiver.png" alt=""/> <figcaption>Puissance installée requise pour garantir une puissance disponible d'1 GW minimum avec un certain taux de disponibilité sur les mois d'hiver, pour l'éolien et le nucléaire. Données du parc français.</figcaption> </figure> <p>Ces graphiques montrent qu’augmenter la taille du parc éolien terrestre au niveau national pour améliorer la sécurité d’approvisionnement est une très mauvaise stratégie sans capacité de stockage. Ce n’est pas le cas pour le nucléaire, car celui-ci n’est effectivement pas “intermittent”. Le discours de la France Insoumise relève d’une stratégie de communication déconnectée de l’expérience. Si les partis délaissent la réflexion et l’analyse critique au profit de la production de slogans, le débat public s’en portera-t-il vraiment mieux ? Que la France Insoumise affirme que le nucléaire est autant sinon plus intermittent que l’éolien interroge aussi sur la stratégie de sortie du nucléaire envisagée. En effet pour Jean-Luc Mélenchon, “On peut fermer les centrales nucléaires en mettant en face la production d’énergies renouvelables qui correspond” <sup id="fnref:6"><a href="#fn:6" class="footnote" rel="footnote" role="doc-noteref">6</a></sup>. Or, comme on le voit sur ces graphes, en aucun cas l’éolien peut apporter la même garantie que le nucléaire et la comparaison est impossible. Si le parc de renouvelables ne couvre pas la demande de manière fiable comme ce sera le cas pour encore longtemps (avant d’avoir suffisamment de surcapacité et de moyens de stockage pour l’absorber), la France Insoumise donnera-t-elle la priorité à la sortie du nucléaire ou à celle des énergies fossiles ?</p> <h2 id="méthodologie">Méthodologie</h2> <p>Pour produire les graphes ci-dessus, j’ai d’abord dérivé la distribution $\tau(q)$ du facteur de charge défini comme $q(t) = P(t)/P_{\text{inst}}$, i.e. le rapport entre la puissance produite par une certaine filière par rapport à la puissance installée pour cette même filière, lequel est compris entre 0 et 1. $\tau(q)$ est ici défini comme la probabilité que le facteur de charge soit supérieur (ou égal) à $q$ et il est très facile de l’obtenir à partir des données. Par exemple, $\tau(q)=1/2$ signifie que le facteur de charge est plus grand que $q$ la moitié de l’année. Je calcule cette distribution pour chaque année $y$ entre 2012 et 2021, que je note $\tau_y(q)$. La fonction réciproque $q_y(\tau)$ donne, pour un taux de disponibilité donné $\tau$ (par exemple $\tau=$ 90%), le facteur de charge garanti $q(\tau)$. J’ai supposé que $q_y(\tau)$ (le facteur de charge garanti) variait d’une année sur l’autre selon une loi Beta (une distribution de probabilité qui est comprise entre 0 et 1, comme $q$), afin de tenir compte des variations dues aux conditions météorologiques d’une année sur l’autre pour l’éolien, et celles dues, par exemple, aux opérations de maintenance et incidents quelconques pour le nucléaire. Mathématiquement, $q_y(\tau) \sim \text{Beta}(\mu_\tau \eta_\tau, (1-\mu_\tau) \eta_\tau)$, où $\mu_\tau \sim \text{uniform}(0,1)$ est la valeur moyenne attendue et $\eta_\tau \sim \text{Pareto}(1,1.5)$ un paramètre qui contrôle l’ampleur des variations d’une année sur l’autre.</p> <p>Enfin, les courbes ci-dessus représentent la distribution de l’inverse de $q$ ($\text{1 GW}/q(\tau)$). Les bandes colorées représentent l’intervalle de probabilité à 90%.</p> <p>Cette méthodologie repose sur la production constatée, laquelle peut-être ajustée en fonction de la demande. Il est probable que la production éolienne soit totalement absorbée, si bien qu’on puisse assimiler le facteur de charge au taux de disponibilité. C’est peut-être moins vrai pour le nucléaire - auquel cas son taux de disponibilité est sous-estimé dans les graphiques ci-dessous.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>https://twitter.com/JLMelenchon/status/1523970032027541504 <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:2"> <p>https://twitter.com/JLMelenchon/status/1491038754978799620 <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:3"> <p>https://www.iea.org/data-and-statistics/data-tables?country=WORLD&amp;energy=Electricity&amp;year=2019 <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:4"> <p>https://odre.opendatasoft.com/explore/dataset/eco2mix-national-cons-def/ <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:5"> <p>https://odre.opendatasoft.com/explore/dataset/registre-national-installation-production-stockage-electricite-agrege/ <a href="#fnref:5" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> <li id="fn:6"> <p>https://twitter.com/JLMelenchon/status/1520541659242668037 <a href="#fnref:6" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="posts"/><category term="transition énergétique"/><category term="éolien"/><category term="énergie nucléaire"/><category term="energy transition"/><category term="nuclear energy"/><category term="wind power"/><category term="français"/><summary type="html"><![CDATA[Des personnalités politiques de premier plan de la France Insoumise affirment depuis plusieurs mois que le nucléaire est une source d’électricité “intermittente” 1, et même bientôt “plus intermittent[e] que l’éolien” si l’on en croit Jean-Luc Mélenchon 2. Ce discours, bien sûr, vise à promouvoir la transition vers 100% d’énergies renouvelables défendue par le parti. Une telle transition impliquerait de fermer les 56 réacteurs actuellement en opération, lesquels ont fourni à la France 70% de son électricité en 2019 3. Une telle tâche n’est pas seulement difficile ; elle est aussi critiquable, alors que l’énergie nucléaire demeure à ce stade la source la plus propre en terme de gaz à effet de serre. Alors que le bien-fondé de la sortie du nucléaire en Allemagne est remise en question par les menaces actuelles sur l’approvisionnement en gaz et par ses conséquences en terme d’émissions de gaz à effet de serre, LFI et ses alliés d’EELV ont besoin de renforcer leurs arguments contre l’énergie nucléaire. Par chance pour eux, le parc nucléaire français rencontre actuellement des difficultés majeures. Environ la moitié des réacteurs sont arrêtés pour des opérations de maintenance, pour diverses raisons, y compris le fameux problème de corrosion sous contrainte anormale identifié sur plusieurs d’entre eux. Il en résulte que la disponibilité du parc nucléaire est actuellement très limitée, et un risque de blackout pour cet hiver. C’est principalement sur la base de cette situation que le nucléaire est qualifié d’“intermittent” par la France Insoumise, et même “bientôt plus intermittent que l’éolien”. https://twitter.com/JLMelenchon/status/1523970032027541504 &#8617; https://twitter.com/JLMelenchon/status/1491038754978799620 &#8617; https://www.iea.org/data-and-statistics/data-tables?country=WORLD&amp;energy=Electricity&amp;year=2019 &#8617;]]></summary></entry><entry><title type="html">Notes on Social Epistemology: Essential Readings</title><link href="https://lucasgautheron.github.io/blog/2022/social-epistemology-post/" rel="alternate" type="text/html" title="Notes on Social Epistemology: Essential Readings"/><published>2022-07-20T00:00:00+00:00</published><updated>2022-07-20T00:00:00+00:00</updated><id>https://lucasgautheron.github.io/blog/2022/social-epistemology-post</id><content type="html" xml:base="https://lucasgautheron.github.io/blog/2022/social-epistemology-post/"><![CDATA[<p>The volume <em>Social Epistemology: Essential Readings</em> <sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup> edited by Alvin I. Goldman and Dennis Whitcomb introduces the topic of social epistemology by bringing together a variety of previously published issues which belong to it. These different chapters are valuable not as much for the originality of the results that they provide, rather than for illustrating the wide scope of questions embodied social epistemology. Readers who are interested like me in diverse topics such as sociology of science, the cultural brain hypothesis in anthropology, or institutional design in political science, will find that social epistemology may provide useful insights beneficial to each of these matters – which is what makes this introduction exciting to read, and the whole enterprise look attractive. It is in light of the diversity of social epistemology, that Alvin I. Goldman proposes that the topic be split into three categories.</p> <p>The first kind of social epistemology departs from more “traditional” individualistic epistemology by considering “individual doxastic agents with social evidence”; it is mostly concerned with how knowledge transmitted by others should be incorporated into one’s beliefs. Typically, this line of inquiry encompasses questions such as: on what grounds one may rationally trust testimonies or experts on certain matters they do not know (much) about? How should peers manage conflicting statements about the truth of certain propositions?</p> <p>The second kind of social epistemology treats social groups such as institutions as epistemic agents themselves, holding their own beliefs. For this reason, it is referred to by Goldman as “collective doxastic agents social epistemology”, or “CDA SE”. A typical issue in that context is the aggregation of conflicting individual beliefs into a single collective judgement. Several contributions address the challenges raised by such a task – for instance, the impossibility for collective judgments to simultaneously fulfill a number of requirements such as their logical consistency is discussed, as well as potential ways out this difficulty. Another interesting issue raised in the volume is under what conditions certain aggregation procedures (such as majority vote) may be more efficient at attaining truth. These questions may be of high relevance for assessing certain kinds of institutional frameworks.</p> <p>The third kind of social epistemology discussed in the book, which Alvin I. Goldman labels as “system oriented social epistemology”, or “SYSOR SE”, goes one step further. It is concerned with the epistemic outcome of certain institutional designs – for instance, what kind of knowledge a given set of institutional rules may produce? The book addresses diverse examples: the truth-conduciveness of aspects of the judiciary system, a comparison of “deliberating groups” versus “prediction markets”, but also a discussion of the epistemic features of Wikipedia.</p> <p>Although the book addresses matters that have very broad implications (including regarding the merits of democracy, the reliability of the media, the epistemic flaws or virtues of certain justice systems, etc.), it is of course of high relevance for studies of science. The obvious fundamental reason is that modern science, in particular “Big Science” (as a massive, large-scale social phenomenon) heavily relies on a complex division of labour and therefore is essentially social.</p> <p>Although there is already quite a record of social studies of science, I find the approach(es) offered by social epistemology quite illuminating in contrast. The reason stems from what is a broad impression which I will not attempt to justify thoroughly. Roughly speaking, “critical” social studies of science sought to demonstrate how social phenomena (e.g. power) challenge certain views of science on which rests its perceived authority. Such work has the effect, arguably justifiably, of diminishing the status of “science” - and as a result it has sometimes been accused of reducing science to the mere pursuit of groups’ interests. I believe that the approach(es) taken on by social epistemology are more positive, by emphasizing the epistemic power of certain processes or institutional arrangements for combining individual knowledge. In that respect the social is not a threat to the significance of knowledge but rather the basis for progress, under conditions which are to be the focus of a fruitful and much needed discussion. For instance, the last chapter of the book “The Communication Structure of Epistemic Communities” (by Kevin J. S.Zollman), illustrates how valuable social epistemology may be to studies of science by providing tools for evaluating the efficiency of certain social networks for learning.</p> <p>Despite the variety of issues regrouped in the book, the ordering of the chapters emphasizes the potential for continuity between these issues and therefore the unity that underlies social epistemology.</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>Goldman, Alvin I. and Dennis Whitcomb (eds), 2011, <em>Social Epistemology: Essential Readings</em>, New York: Oxford University Press <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name></name></author><category term="posts"/><category term="social epistemology"/><category term="social studies of science"/><category term="english"/><summary type="html"><![CDATA[The volume Social Epistemology: Essential Readings 1 edited by Alvin I. Goldman and Dennis Whitcomb introduces the topic of social epistemology by bringing together a variety of previously published issues which belong to it. These different chapters are valuable not as much for the originality of the results that they provide, rather than for illustrating the wide scope of questions embodied social epistemology. Readers who are interested like me in diverse topics such as sociology of science, the cultural brain hypothesis in anthropology, or institutional design in political science, will find that social epistemology may provide useful insights beneficial to each of these matters – which is what makes this introduction exciting to read, and the whole enterprise look attractive. It is in light of the diversity of social epistemology, that Alvin I. Goldman proposes that the topic be split into three categories. Goldman, Alvin I. and Dennis Whitcomb (eds), 2011, Social Epistemology: Essential Readings, New York: Oxford University Press &#8617;]]></summary></entry><entry><title type="html">L’Esprit Public, une émission privatisée sur France Culture</title><link href="https://lucasgautheron.github.io/posts/2018/05/lesprit-public-une-emission-privatisee-sur-france-culture/" rel="alternate" type="text/html" title="L’Esprit Public, une émission privatisée sur France Culture"/><published>2018-05-14T00:00:00+00:00</published><updated>2018-05-14T00:00:00+00:00</updated><id>https://lucasgautheron.github.io/posts/2018/05/lesprit-public</id><content type="html" xml:base="https://lucasgautheron.github.io/posts/2018/05/lesprit-public-une-emission-privatisee-sur-france-culture/"><![CDATA[<p>Chaque dimanche de onze heures à midi, Émilie Aubry anime « L’Esprit Public » sur <em>France Culture</em>, présentée comme une « mise en perspective de l’actualité politique au cours d’un débat d’intellectuels engagés ». La page de l’émission avertit ses auditeurs : ceux-ci doivent s’attendre à de la « polémique », et même de l’« impertinence ».</p> <p>Les sujets traités, en général deux par émission, sont extrêmement variés. Ainsi, parmi les thématiques abordées, on compte entre-autres la situation des migrants, la réforme de l’université, l’évasion fiscale, le féminisme, la France-Afrique, le Brexit… On s’attendrait donc à ce que la diversité des profils des invités - au nombre de trois à quatre par émission - corresponde à celle des questions abordées, ne serait-ce parce qu’il est difficilement concevable qu’un seul et même « intellectuel engagé », aussi brillant soit-il, soit le plus pertinent pour s’exprimer sur tous ces sujets à la fois.</p> <p>La réalité est bien différente. Ainsi, seize personnes ont monopolisé à elles seules la totalité des invitations (110) aux 29 émissions enregistrées entre le 1er octobre 2017 et le 13 mai 2018. Pire que cela, cinq invités se sont accaparés la moitié (54) de ces invitations. Ainsi, Thierry Pech, invité douze fois sur la période, s’est exprimé sur des sujets comme la « diplomatie », les « banlieues », la Syrie, l’Université, le terrorisme, la Libye, l’affaire Ramadan, la Corse, le socialisme, les réfugiés, Vladimir Poutine, ou encore le climat.</p> <p><img src="/assets/img/lesprit-public/invites.png" alt="Répartition des invitations aux 29 émissions enregistrées entre le 01/10/2017 et le 13/05/2018."/></p> <p>La poignée d’invités convoqués sur tous ces sujets ne pouvant se prévaloir d’une « expertise » aussi large, la « mise en perspective de l’actualité politique » ressemble davantage à un exposé de lieux communs, et le « débat d’intellectuels engagés » à des bavardages. Une tranche d’une heure sur le service public, privatisée par quelques habitués pour converser tranquillement.</p> <p>Quid de la « polémique » et de l’« impertinence » promises ? Là encore, les chiffres sont éclairants. La moitié des invités a des liens partisans directs (membres ou soutiens publics de partis politiques, candidats sous étiquette, participations à des gouvernements). En regroupant les invitations par affiliation partisane, on constate que 60 % d’entre-elles ont été accordées à des personnalités ayant des liens directs avec <em>Les Républicains</em>, le <em>Parti Socialiste</em> ou <em>En Marche</em>, des partis au fort dénominateur commun idéologique néolibéral. Sans compter les invités sans lien partisan direct, mais ouvertement libéraux, comme Monique Canto Sperber ou encore Philippe Manière.</p> <p><img src="/assets/img/lesprit-public/partis.png" alt="Répartition par parti politique des invitations aux 29 émissions enregistrées entre le 01/10/2017 et le 13/05/2018."/></p> <p>Dans ces circonstances, non seulement l’émission est monopolisée par un petit club restreint, mais en plus celui-ci manque cruellement de pluralisme : des intellectuels engagés, oui… mais dans la même direction. Finalement, le hasard fait bien les choses : l’emplacement de l’émission dans la grille des programmes de France Culture correspond tout-à-fait à son ton de conversations de déjeuners dominicaux en bonne famille. Au risque d’une légère contradiction avec la mission de service public de la station.</p>]]></content><author><name></name></author><category term="posts"/><category term="médias"/><summary type="html"><![CDATA[Chaque dimanche de onze heures à midi, Émilie Aubry anime « L’Esprit Public » sur France Culture, présentée comme une « mise en perspective de l’actualité politique au cours d’un débat d’intellectuels engagés ». La page de l’émission avertit ses auditeurs : ceux-ci doivent s’attendre à de la « polémique », et même de l’« impertinence ».]]></summary></entry></feed>